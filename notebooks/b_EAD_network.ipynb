{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse exploratoire des données Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librairies\n",
    "import pandas as pd\n",
    "from pickleshare import PickleShareDB\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.subplots as sp\n",
    "from plotly.graph_objs import Bar\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous chargeons les données depuis le fichier des données préprarées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données nettoyées\n",
    "db = PickleShareDB('../prep_data/kity')\n",
    "\n",
    "df_net_1 = db['net_attack_1_clean']\n",
    "df_net_2 = db['net_attack_2_clean']\n",
    "df_net_3 = db['net_attack_3_clean']\n",
    "df_net_4 = db['net_attack_4_clean']\n",
    "df_net_norm = db['net_norm_clean']\n",
    "\n",
    "# Données brutes\n",
    "'''\n",
    "df_net_1 = pd.read_csv('../datasets/Network datatset/csv/attack_1.csv')\n",
    "df_net_2 = pd.read_csv('../datasets/Network datatset/csv/attack_2.csv')\n",
    "df_net_3 = pd.read_csv('../datasets/Network datatset/csv/attack_3.csv')\n",
    "df_net_4 = pd.read_csv('../datasets/Network datatset/csv/attack_4.csv')\n",
    "df_net_norm = pd.read_csv('../datasets/Network datatset/csv/normal.csv')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nombre de valeurs unique par colonne pour chaque dataset\n",
    "nunique_1 = df_net_1.nunique()\n",
    "nunique_2 = df_net_2.nunique()\n",
    "nunique_3 = df_net_3.nunique()\n",
    "nunique_4 = df_net_4.nunique()\n",
    "nunique_norm = df_net_norm.nunique()\n",
    "print(nunique_1)\n",
    "print(nunique_2)\n",
    "print(nunique_3)\n",
    "print(nunique_4)\n",
    "print(nunique_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous commençons par observer le premier, comme ils doivent à priori avoir la même structure, pour comprendre les données que l'on a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_net_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des différents types de colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colonnes de chaque type\n",
    "df_bool = df_net_1.select_dtypes(include='bool')\n",
    "print(\"Colonnes de type booléen : \\n\", df_bool.columns,\"\\n\")\n",
    "\n",
    "df_obj = df_net_1.select_dtypes(include='object')\n",
    "print(\"Colonnes de type objet : \\n\",df_obj.columns,\"\\n\")\n",
    "\n",
    "df_cat = df_net_1.select_dtypes(include='category')\n",
    "print(\"Colonnes de type catégorie : \\n\", df_cat.columns,\"\\n\")\n",
    "\n",
    "df_num = df_net_1.select_dtypes(include='number')\n",
    "print(\"Colonnes de type nombre : \\n\", df_num.columns,\"\\n\")  \n",
    "\n",
    "df_time = df_net_1.select_dtypes(include='datetime')\n",
    "print(\"Colonnes de type datetime : \\n\", df_time.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse colonnes booléennes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=len(df_bool.columns), subplot_titles=df_bool.columns)\n",
    "\n",
    "for i, col in enumerate(df_bool.columns):\n",
    "    value_counts = df_bool[col].value_counts()\n",
    "    fig.add_trace(go.Bar(x=value_counts.index, y=value_counts.values, name=col), row=1, col=i+1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=300, width=500, title=\"Fréquence des valeurs uniques par colonne (category)\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des colonnes numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_num.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistiques descriptives\n",
    "desc_stats = df_num.describe()\n",
    "desc_stats = desc_stats.drop('count') # suppression de la colonne count pour la visualisation\n",
    "\n",
    "fig = make_subplots(rows=1, cols=len(desc_stats.columns), subplot_titles=desc_stats.columns)\n",
    "for i, col in enumerate(desc_stats.columns):\n",
    "    fig.add_trace(go.Bar(x=desc_stats.index, y=desc_stats[col], name=col),row=1, col=i+1)\n",
    "\n",
    "fig.update_layout(height=700, width=1200,title=\"Statistiques descriptives par colonne\",showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des valeurs pour chaque colonne\n",
    "for col in df_num.columns:\n",
    "    print(col, df_num[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=len(df_cat.columns), subplot_titles=df_cat.columns)\n",
    "\n",
    "for i, col in enumerate(df_cat.columns):\n",
    "    value_counts = df_cat[col].value_counts().head(10)  # Pour éviter d'avoir trop de valeurs\n",
    "    fig.add_trace(go.Bar(x=value_counts.index, y=value_counts.values, name=col), row=1, col=i+1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=700, width=1300, title=\"Fréquence des valeurs uniques par colonne (category)\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Répartition des valeurs pour chaque colonne (graphique)\n",
    "columns = df_num.columns\n",
    "titles = [\"Size\", \"n_pkt_src\", \"n_pkt_dst\"]\n",
    "\n",
    "fig = sp.make_subplots(rows=2, cols=2, subplot_titles=titles, vertical_spacing=0.1, horizontal_spacing=0.15)\n",
    "for i, col in enumerate(columns):\n",
    "    row = (i // 2) + 1\n",
    "    col_position = (i % 2) + 1\n",
    "    fig.add_trace(Bar(x=df_num[col].value_counts().index, y=df_num[col].value_counts().values, name=titles[i]),row=row, col=col_position)\n",
    "\n",
    "fig.update_layout(height=700, width=700, title_text=\"Distribution des valeurs dans les colonnes numériques\",showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sport\n",
    "    - Distribution : Forte concentration de valeurs spécifiques (port 502 par exemple qui est spécifique aux Modbus), certains ports moins représentés pourrait être des accès interdits\n",
    "\n",
    "- dport\n",
    "    - Comme pour sport, la majorité des paquets sont concentrés sur quelques ports de destination, avec le port 502 comme destination principale. \\\n",
    "    Des valeurs plus rares sont observées, mais elles sont peu fréquentes. Cela pourrait également être des attaques.\n",
    "\n",
    "- flags\n",
    "    - La plupart des valeurs sont à 11000, forte concentration autour de valeurs spécifiques (états standards de connexion ??)\n",
    "    - La majorité des paquets ont des flags identiques, ce qui est attendu pour des communications stables. \\\n",
    "    Quelques variations existent, ce qui peut représenter des tentatives d’intrusion ou des anomalies.\n",
    "\n",
    "- size\n",
    "    - Tailles de paquets concentrées autour de valeurs entre 64 et 66 octets + peu de variation\n",
    "    - Distribution fortement centrée sur 66 octets (taille de paquets standard pour les échanges de données Modbus ??) \\\n",
    "    --> paquets d'autres tailles pourraient être intéressants à analyser pour des comportements anormaux\n",
    "\n",
    "- n_pkt_src\n",
    "    - La distribution présente des pics élevés pour certaines valeurs spécifiques (flux réguliers de données ?? surcharge ou un potentiel DoS ???)\n",
    "\n",
    "- n_pkt_dst\n",
    "    - Pics dans la distribution indiquent des destinations qui reçoivent un grand nombre de paquets ?? anomalies ??\n",
    "\n",
    "- label_n\n",
    "    - Valeurs sont binaires (0 ou 1), avec 0 = paquets normaux et 1 attaque\n",
    "    -La majorité des paquets sont normaux, donc dataset déséquilibré MAIS représentatif ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des colonnes catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs uniques pour chaque colonne\n",
    "for col in df_cat.columns:\n",
    "    print(col, df_cat[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=len(df_cat.columns), subplot_titles=df_cat.columns)\n",
    "\n",
    "for i, col in enumerate(df_cat.columns):\n",
    "    value_counts = df_cat[col].value_counts().head(10)  # Pour éviter d'avoir trop de valeurs\n",
    "    fig.add_trace(go.Bar(x=value_counts.index, y=value_counts.values, name=col), row=1, col=i+1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=700, width=1300, title=\"Fréquence des valeurs uniques par colonne (category)\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des colonnes de type objet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valeurs uniques pour chaque colonne\n",
    "for col in df_obj.columns:\n",
    "    print(col, df_obj[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=len(df_obj.columns), subplot_titles=df_obj.columns)\n",
    "\n",
    "for i, col in enumerate(df_obj.columns):\n",
    "    value_counts = df_obj[col].value_counts().head(10)  # Pour éviter d'avoir trop de valeurs\n",
    "    fig.add_trace(go.Bar(x=value_counts.index, y=value_counts.values, name=col), row=1, col=i+1)\n",
    "\n",
    "\n",
    "fig.update_layout(height=700, width=1300, title=\"Fréquence des valeurs uniques par colonne (object)\", showlegend=False)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- mac_s, mac_d : \n",
    "    - une adresse principale largement dominante \n",
    "    - trafic centré autour de quelques appareils\n",
    "    - autres sont peut-être anormales\n",
    "\n",
    "- ip_s, ip_d : \n",
    "    - adresses IP source et destination également dominées par quelques valeurs\n",
    "    - communication entre des hôtes spécifiques\n",
    "\n",
    "- proto : \n",
    "    - protocole Modbus de loin le plus utilisé,\n",
    "    - confirme l’utilisation majoritaire de Modbus dans le système\n",
    "\n",
    "- modbus_fn : \n",
    "    - Les fonctions Modbus, toutes utilisées de façon plus ou moins équivalentes\n",
    "    - Quelques valeurs inconnues, peut-être attaques\n",
    "\n",
    "- modbus_response : \n",
    "    - réponse \"Pas de réponse\" dominante, surement représentant une exécution correcte\n",
    "    - autres valeurs beaucoup moins présentes\n",
    "\n",
    "- label : \n",
    "    - majorité des données marquées comme normales\n",
    "    - autres valeurs non normales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrice de corrélation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice dans le dataset normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_net_norm\n",
    "\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "#print(f\"Matrice de corrélation pour le DataFrame {dataframes.index(df) + 1}\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "fig = px.imshow(correlation_matrix, title=\"Matrice de corrélation du dataset normal\", color_continuous_scale=\"blues\", zmin=-1, zmax=1, height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons voir que ip_s, sport et n_pkt_src sont très corrélés, de même pour ip_d, dport et n_pkt_dst. \\\n",
    "Il y a également une forte corrélation négative entre les ports/ip sources et ceux de destination \\\n",
    "Cela semble plutot logique, car les échanges sont normalement entre les mêmes appareils."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_net_1\n",
    "\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "#print(f\"Matrice de corrélation pour le DataFrame {dataframes.index(df) + 1}\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "fig = px.imshow(correlation_matrix, title=\"Matrice de corrélation du dataset attack 1\", color_continuous_scale=\"blues\", zmin=-1, zmax=1, height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peu de différence avec le dataset normale, il va être compliqué de détecter des anomalies dans ce dataset. \\\n",
    "Surement dû au fait que les attaques sont physique en grande partie dans ce dataset, et donc non détectable sur des données réseaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_net_2\n",
    "\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "#print(f\"Matrice de corrélation pour le DataFrame {dataframes.index(df) + 1}\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "fig = px.imshow(correlation_matrix, title=\"Matrice de corrélation du dataset attack 2\", color_continuous_scale=\"blues\", zmin=-1, zmax=1, height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_net_3\n",
    "\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "#print(f\"Matrice de corrélation pour le DataFrame {dataframes.index(df) + 1}\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "fig = px.imshow(correlation_matrix, title=\"Matrice de corrélation du dataset attack 3\", color_continuous_scale=\"blues\", zmin=-1, zmax=1, height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_net_4\n",
    "\n",
    "object_cols = df.select_dtypes(include=['object']).columns\n",
    "le = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "#print(f\"Matrice de corrélation pour le DataFrame {dataframes.index(df) + 1}\")\n",
    "#print(correlation_matrix)\n",
    "\n",
    "fig = px.imshow(correlation_matrix, title=\"Matrice de corrélation du dataset attack 4\", color_continuous_scale=\"blues\", zmin=-1, zmax=1, height=600, width=600)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces 3 dataset ont des matrices de corrélations assez différentes du dataset normale. \\\n",
    "Ces dataset ont des attaques physiques en moindre quantités comme vu précédemment (notebook_network_preparation.ipynb), il est donc plus facile de détecter les attaques qui sont visibles sur les données réseau."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supposons que 'ecart' est une série Pandas contenant les écarts de temps en secondes\n",
    "ecart_filtered = ecart.dropna()  # Supprimer les valeurs manquantes\n",
    "\n",
    "# Créer un histogramme avec Plotly\n",
    "fig = px.histogram(\n",
    "    ecart_filtered, \n",
    "    nbins=1000,  # Nombre de bins\n",
    "    title='Distribution des écarts de temps',\n",
    "    labels={'value': 'Écarts de temps (secondes)', 'count': 'Fréquence'}\n",
    ")\n",
    "\n",
    "# Ajuster les limites de l'axe X\n",
    "fig.update_xaxes(range=[0, 0.004])\n",
    "\n",
    "# Personnalisation du graphique\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Écarts de temps (secondes)\",\n",
    "    yaxis_title=\"Fréquence\"\n",
    ")\n",
    "\n",
    "# Afficher le graphique\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'acquisition des données n'est pas à la même fréquence que celle des données physiques. En effet, les données physiques sont enregistrées toutes les 1s, tandis qu'ici, il n'y a pas d'enregistrement continue. \n",
    "\n",
    "Les données sont enregistrées lorsqu'il y a une interraction réseau."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
