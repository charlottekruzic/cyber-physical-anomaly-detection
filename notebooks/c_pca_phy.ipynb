{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse ACP des données physiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickleshare import PickleShareDB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from prep_data\n",
    "data_dir = '../prep_data' \n",
    "db = PickleShareDB(os.path.join(data_dir, 'kity'))\n",
    "\n",
    "# Load all physical datasets\n",
    "df_phy_1 = db['df_phy_1']\n",
    "df_phy_2 = db['df_phy_2']\n",
    "df_phy_3 = db['df_phy_3']\n",
    "df_phy_4 = db['df_phy_4']\n",
    "df_phy_norm = db['df_phy_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets and add source column\n",
    "dfs = []\n",
    "for df, name in zip(\n",
    "    [df_phy_1, df_phy_2, df_phy_3, df_phy_4, df_phy_norm],\n",
    "    ['phy_1', 'phy_2', 'phy_3', 'phy_4', 'phy_norm']\n",
    "):\n",
    "    df = df.copy()\n",
    "    df['source'] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Combined shape:\", df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for PCA\n",
    "# We'll exclude Time, Label columns, and boolean columns\n",
    "numeric_features = df_combined.select_dtypes(include=[np.number]).columns\n",
    "features_for_pca = [col for col in numeric_features \n",
    "                    if col not in ['Label_n'] \n",
    "                    and not col.startswith('Valv_') \n",
    "                    and not col.startswith('Pump_')]\n",
    "\n",
    "print(\"Features selected for PCA:\")\n",
    "print(features_for_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and scale them\n",
    "X = df_combined[features_for_pca]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features_for_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Détermination du nombre optimal de composantes\n",
    "\n",
    "En se basant sur l'analyse de la variance expliquée ci-dessus, nous pouvons choisir le nombre optimal de composantes. Nous cherchons typiquement à capturer 80-90% de la variance tout en gardant un nombre de composantes gérable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA with maximum number of components\n",
    "pca_var = PCA(n_components=len(features_for_pca))\n",
    "pca_var.fit(X_scaled)\n",
    "\n",
    "# Calculate explained variance and cumulative explained variance\n",
    "explained_variance = pca_var.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "variance_df = pd.DataFrame({\n",
    "    'Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "    'Explained_Variance': explained_variance,\n",
    "    'Cumulative_Variance': cumulative_variance\n",
    "})\n",
    "\n",
    "# Plot explained variance\n",
    "fig = go.Figure()\n",
    "\n",
    "# Bar plot for individual explained variance\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=variance_df['Component'],\n",
    "        y=variance_df['Explained_Variance'],\n",
    "        name='Individual',\n",
    "        text=variance_df['Explained_Variance'].round(3),\n",
    "        textposition='auto',\n",
    "    )\n",
    ")\n",
    "\n",
    "# Line plot for cumulative explained variance\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=variance_df['Component'],\n",
    "        y=variance_df['Cumulative_Variance'],\n",
    "        name='Cumulative',\n",
    "        line=dict(color='red'),\n",
    "        mode='lines+markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Explained Variance Ratio by Principal Component',\n",
    "    xaxis_title='Principal Component',\n",
    "    yaxis_title='Explained Variance Ratio',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print cumulative variance table\n",
    "print(\"Cumulative Explained Variance:\")\n",
    "for i, cum_var in enumerate(cumulative_variance):\n",
    "    print(f\"PC{i+1}: {cum_var:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA with selected number of components\n",
    "n_components = 5\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create DataFrame with transformed data\n",
    "pca_df = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "# Add labels and source information\n",
    "pca_df['Label'] = df_combined['Label']\n",
    "pca_df['Label_n'] = df_combined['Label_n']\n",
    "pca_df['source'] = df_combined['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des résultats ACP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Scatter plot colored by Label\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='Label',\n",
    "    title='PCA Results - First Two Components',\n",
    "    hover_data=['source']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Label',\n",
    "    title='PCA Results - First Three Components',\n",
    "    hover_data=['source']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de l'importance des caractéristiques  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance heatmap\n",
    "components_df = pd.DataFrame(\n",
    "    pca.components_,\n",
    "    columns=features_for_pca,\n",
    "    index=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "fig = px.imshow(\n",
    "    components_df,\n",
    "    title='PCA Components Matrix Heatmap',\n",
    "    aspect='auto',\n",
    "    color_continuous_scale='RdBu'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top contributing features for each component\n",
    "for i in range(n_components):\n",
    "    print(f\"\\nTop features contributing to PC{i+1}:\")\n",
    "    # Get absolute values of component coefficients\n",
    "    pc = np.abs(pca.components_[i])\n",
    "    # Sort features by importance\n",
    "    feature_importance = sorted(zip(features_for_pca, pc), key=lambda x: x[1], reverse=True)\n",
    "    for feature, importance in feature_importance[:5]:\n",
    "        print(f\"{feature}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sauvegarder les résultats dans PickleShareDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA results for use in Streamlit\n",
    "pca_results = {\n",
    "    'transformed_data': pca_df,\n",
    "    'explained_variance': variance_df,\n",
    "    'components_matrix': components_df,\n",
    "    'feature_names': features_for_pca,\n",
    "    'pca_model': pca,\n",
    "    'scaler': scaler\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse ACP pour la classification binaire (normale vs attaque)\n",
    "\n",
    "Pour compléter notre analyse, nous allons également examiner comment l'ACP se comporte dans le cas d'une classification binaire simple, en distinguant uniquement les états normaux des attaques. Cette approche nous permettra de mieux comprendre la séparation globale entre le comportement normal et anormal du système."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations for binary classification (Label_n)\n",
    "# 2D Scatter plot colored by Label_n\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='Label_n',\n",
    "    title='Résultats ACP - Deux Premières Composantes (Classification Binaire)',\n",
    "    hover_data=['source'],\n",
    "    color_discrete_map={True: 'red', False: 'blue'},\n",
    "    labels={'Label_n': 'Attaque'}\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "# 3D Scatter plot for binary classification\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Label_n',\n",
    "    title='Résultats ACP - Trois Premières Composantes (Classification Binaire)',\n",
    "    hover_data=['source'],\n",
    "    color_discrete_map={True: 'red', False: 'blue'},\n",
    "    labels={'Label_n': 'Attaque'}\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de la séparation binaire\n",
    "\n",
    "Les visualisations ci-dessus nous permettent d'observer la séparation entre les états normaux et les attaques dans l'espace réduit par l'ACP. Cette représentation binaire peut être particulièrement utile pour :\n",
    "- Évaluer la facilité de détection globale des attaques\n",
    "- Identifier les zones de chevauchement potentielles entre comportement normal et anormal\n",
    "- Repérer d'éventuels regroupements d'attaques dans l'espace des composantes principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate centroids for normal and attack states\n",
    "centroids = pca_df.groupby('Label_n')[['PC1', 'PC2', 'PC3']].mean()\n",
    "\n",
    "# Create visualization with centroids\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add scatter points\n",
    "for label, color in [(False, 'blue'), (True, 'red')]:\n",
    "    mask = pca_df['Label_n'] == label\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=pca_df[mask]['PC1'],\n",
    "        y=pca_df[mask]['PC2'],\n",
    "        mode='markers',\n",
    "        name='Normal' if not label else 'Attaque',\n",
    "        marker=dict(color=color, size=5, opacity=0.6)\n",
    "    ))\n",
    "    \n",
    "    # Add centroid\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[centroids.loc[label, 'PC1']],\n",
    "        y=[centroids.loc[label, 'PC2']],\n",
    "        mode='markers',\n",
    "        name=f\"Centroïde {'Normal' if not label else 'Attaque'}\",\n",
    "        marker=dict(\n",
    "            color=color,\n",
    "            size=15,\n",
    "            symbol='x',\n",
    "            line=dict(width=2, color='black')\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Résultats ACP avec Centroïdes (Classification Binaire)',\n",
    "    xaxis_title='PC1',\n",
    "    yaxis_title='PC2'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Update PCA results dictionary with binary analysis\n",
    "pca_results.update({\n",
    "    'binary_centroids': centroids,\n",
    "    'binary_vis_data': {\n",
    "        'pca_df': pca_df,  # We already have the transformed data with Label_n\n",
    "        'color_map': {True: 'red', False: 'blue'},\n",
    "        'label_map': {True: 'Attaque', False: 'Normal'}\n",
    "    }\n",
    "})\n",
    "\n",
    "# Save updated results\n",
    "db['pca_results_phy'] = pca_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_protection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
