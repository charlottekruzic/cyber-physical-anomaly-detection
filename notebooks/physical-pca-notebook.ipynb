{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis of Physical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickleshare import PickleShareDB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from prep_data\n",
    "data_dir = '../prep_data' \n",
    "db = PickleShareDB(os.path.join(data_dir, 'kity'))\n",
    "\n",
    "# Load all physical datasets\n",
    "df_phy_1 = db['df_phy_1']\n",
    "df_phy_2 = db['df_phy_2']\n",
    "df_phy_3 = db['df_phy_3']\n",
    "df_phy_4 = db['df_phy_4']\n",
    "df_phy_norm = db['df_phy_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all datasets and add source column\n",
    "dfs = []\n",
    "for df, name in zip(\n",
    "    [df_phy_1, df_phy_2, df_phy_3, df_phy_4, df_phy_norm],\n",
    "    ['phy_1', 'phy_2', 'phy_3', 'phy_4', 'phy_norm']\n",
    "):\n",
    "    df = df.copy()\n",
    "    df['source'] = name\n",
    "    dfs.append(df)\n",
    "\n",
    "df_combined = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Combined shape:\", df_combined.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features for PCA\n",
    "# We'll exclude Time, Label columns, and boolean columns\n",
    "numeric_features = df_combined.select_dtypes(include=[np.number]).columns\n",
    "features_for_pca = [col for col in numeric_features \n",
    "                    if col not in ['Label_n'] \n",
    "                    and not col.startswith('Valv_') \n",
    "                    and not col.startswith('Pump_')]\n",
    "\n",
    "print(\"Features selected for PCA:\")\n",
    "print(features_for_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and scale them\n",
    "X = df_combined[features_for_pca]\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame for easier handling\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=features_for_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determining Optimal Number of Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit PCA with maximum number of components\n",
    "pca_var = PCA(n_components=len(features_for_pca))\n",
    "pca_var.fit(X_scaled)\n",
    "\n",
    "# Calculate explained variance and cumulative explained variance\n",
    "explained_variance = pca_var.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Create DataFrame for visualization\n",
    "variance_df = pd.DataFrame({\n",
    "    'Component': [f'PC{i+1}' for i in range(len(explained_variance))],\n",
    "    'Explained_Variance': explained_variance,\n",
    "    'Cumulative_Variance': cumulative_variance\n",
    "})\n",
    "\n",
    "# Plot explained variance\n",
    "fig = go.Figure()\n",
    "\n",
    "# Bar plot for individual explained variance\n",
    "fig.add_trace(\n",
    "    go.Bar(\n",
    "        x=variance_df['Component'],\n",
    "        y=variance_df['Explained_Variance'],\n",
    "        name='Individual',\n",
    "        text=variance_df['Explained_Variance'].round(3),\n",
    "        textposition='auto',\n",
    "    )\n",
    ")\n",
    "\n",
    "# Line plot for cumulative explained variance\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=variance_df['Component'],\n",
    "        y=variance_df['Cumulative_Variance'],\n",
    "        name='Cumulative',\n",
    "        line=dict(color='red'),\n",
    "        mode='lines+markers'\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Explained Variance Ratio by Principal Component',\n",
    "    xaxis_title='Principal Component',\n",
    "    yaxis_title='Explained Variance Ratio',\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print cumulative variance table\n",
    "print(\"Cumulative Explained Variance:\")\n",
    "for i, cum_var in enumerate(cumulative_variance):\n",
    "    print(f\"PC{i+1}: {cum_var:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the explained variance analysis above, we can choose the optimal number of components. We typically want to capture 80-90% of the variance while keeping the number of components manageable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA with selected number of components\n",
    "n_components = 3  # Adjust based on explained variance analysis\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Create DataFrame with transformed data\n",
    "pca_df = pd.DataFrame(\n",
    "    X_pca,\n",
    "    columns=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "# Add labels and source information\n",
    "pca_df['Label'] = df_combined['Label']\n",
    "pca_df['Label_n'] = df_combined['Label_n']\n",
    "pca_df['source'] = df_combined['source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing PCA Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Scatter plot colored by Label\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='Label',\n",
    "    title='PCA Results - First Two Components',\n",
    "    hover_data=['source']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D Scatter plot\n",
    "fig = px.scatter_3d(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Label',\n",
    "    title='PCA Results - First Three Components',\n",
    "    hover_data=['source']\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature importance heatmap\n",
    "components_df = pd.DataFrame(\n",
    "    pca.components_,\n",
    "    columns=features_for_pca,\n",
    "    index=[f'PC{i+1}' for i in range(n_components)]\n",
    ")\n",
    "\n",
    "fig = px.imshow(\n",
    "    components_df,\n",
    "    title='PCA Components Matrix Heatmap',\n",
    "    aspect='auto',\n",
    "    color_continuous_scale='RdBu'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top contributing features for each component\n",
    "for i in range(n_components):\n",
    "    print(f\"\\nTop features contributing to PC{i+1}:\")\n",
    "    # Get absolute values of component coefficients\n",
    "    pc = np.abs(pca.components_[i])\n",
    "    # Sort features by importance\n",
    "    feature_importance = sorted(zip(features_for_pca, pc), key=lambda x: x[1], reverse=True)\n",
    "    for feature, importance in feature_importance[:5]:\n",
    "        print(f\"{feature}: {importance:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results to PickleShareDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save PCA results for use in Streamlit\n",
    "pca_results = {\n",
    "    'transformed_data': pca_df,\n",
    "    'explained_variance': variance_df,\n",
    "    'components_matrix': components_df,\n",
    "    'feature_names': features_for_pca,\n",
    "    'pca_model': pca,\n",
    "    'scaler': scaler\n",
    "}\n",
    "\n",
    "db['pca_results_phy'] = pca_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_protection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
